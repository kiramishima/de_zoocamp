{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1: Redpanda version\n",
    "\n",
    "[](https://github.com/DataTalksClub/data-engineering-zoomcamp/blob/main/cohorts/2024/06-streaming/homework.md#question-1-redpanda-version)\n",
    "\n",
    "Now let's find out the version of redpandas.\n",
    "\n",
    "For that, check the output of the command `rpk help` _inside the container_. The name of the container is `redpanda-1`.\n",
    "\n",
    "Find out what you need to execute based on the `help` output.\n",
    "\n",
    "What's the version, based on the output of the command you executed? (copy the entire version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rpk is the Redpanda CLI & toolbox\n",
      "\n",
      "Usage:\n",
      "  rpk [command]\n",
      "\n",
      "Available Commands:\n",
      "  acl         Manage ACLs and SASL users\n",
      "  cloud       Interact with Redpanda cloud\n",
      "  cluster     Interact with a Redpanda cluster\n",
      "  container   Manage a local container cluster\n",
      "  debug       Debug the local Redpanda process\n",
      "  generate    Generate a configuration template for related services\n",
      "  group       Describe, list, and delete consumer groups and manage their offsets\n",
      "  help        Help about any command\n",
      "  iotune      Measure filesystem performance and create IO configuration file\n",
      "  plugin      List, download, update, and remove rpk plugins\n",
      "  redpanda    Interact with a local Redpanda process\n",
      "  topic       Create, delete, produce to and consume from Redpanda topics\n",
      "  version     Check the current version\n",
      "  wasm        Deploy and remove inline WASM engine scripts\n",
      "\n",
      "Flags:\n",
      "  -h, --help      Help for rpk\n",
      "  -v, --verbose   Enable verbose logging (default: false)\n",
      "\n",
      "Use \"rpk [command] --help\" for more information about a command.\n"
     ]
    }
   ],
   "source": [
    "!docker compose exec redpanda-1 rpk help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v22.3.5 (rev 28b2443)\n"
     ]
    }
   ],
   "source": [
    "!docker compose exec redpanda-1 rpk version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2. Creating a topic\n",
    "\n",
    "[](https://github.com/DataTalksClub/data-engineering-zoomcamp/blob/main/cohorts/2024/06-streaming/homework.md#question-2-creating-a-topic)\n",
    "\n",
    "Before we can send data to the redpanda server, we need to create a topic. We do it also with the `rpk` command we used previously for figuring out the version of redpandas.\n",
    "\n",
    "Read the output of `help` and based on it, create a topic with name `test-topic`\n",
    "\n",
    "What's the output of the command for creating a topic?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOPIC       STATUS\n",
      "test-topic  OK\n"
     ]
    }
   ],
   "source": [
    "!docker compose exec redpanda-1 rpk topic create test-topic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3. Connecting to the Kafka server\n",
    "\n",
    "[](https://github.com/DataTalksClub/data-engineering-zoomcamp/blob/main/cohorts/2024/06-streaming/homework.md#question-3-connecting-to-the-kafka-server)\n",
    "\n",
    "We need to make sure we can connect to the server, so later we can send some data to its topics\n",
    "\n",
    "First, let's install the kafka connector (up to you if you want to have a separate virtual environment for that)\n",
    "\n",
    "```shell\n",
    "pip install kafka-python\n",
    "```\n",
    "\n",
    "You can start a jupyter notebook in your solution folder or create a script\n",
    "\n",
    "Let's try to connect to our server:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import time\n",
    "from kafka import KafkaProducer\n",
    "\n",
    "def json_serializer(data):\n",
    "    return json.dumps(data).encode('utf-8')\n",
    "\n",
    "server = 'localhost:9092'\n",
    "\n",
    "producer = KafkaProducer(\n",
    "    bootstrap_servers=[server],\n",
    "    value_serializer=json_serializer\n",
    ")\n",
    "\n",
    "producer.bootstrap_connected()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provided that you can connect to the server, what's the output of the last command?\n",
    "\n",
    "R= **True**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4. Sending data to the stream\n",
    "\n",
    "[](https://github.com/DataTalksClub/data-engineering-zoomcamp/blob/main/cohorts/2024/06-streaming/homework.md#question-4-sending-data-to-the-stream)\n",
    "\n",
    "Now we're ready to send some test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sent: {'number': 0}\n",
      "Sent: {'number': 1}\n",
      "Sent: {'number': 2}\n",
      "Sent: {'number': 3}\n",
      "Sent: {'number': 4}\n",
      "Sent: {'number': 5}\n",
      "Sent: {'number': 6}\n",
      "Sent: {'number': 7}\n",
      "Sent: {'number': 8}\n",
      "Sent: {'number': 9}\n",
      "sending messages took 0.51 seconds\n",
      "final step took 0.51 seconds\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "topic_name = 'test-topic'\n",
    "\n",
    "for i in range(10):\n",
    "    message = {'number': i}\n",
    "    producer.send(topic_name, value=message)\n",
    "    print(f\"Sent: {message}\")\n",
    "    time.sleep(0.05)\n",
    "t2 = time.time()\n",
    "print(f'sending messages took {(t2 - t0):.2f} seconds')\n",
    "producer.flush()\n",
    "\n",
    "t1 = time.time()\n",
    "print(f'final step took {(t1 - t0):.2f} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How much time did it take? Where did it spend most of the time?\n",
    "\n",
    "Sending the messages -> 0.51\n",
    "Flushing -> 0.51\n",
    "Both took approximately the same amount of time\n",
    "(Don't remove time.sleep when answering this question)\n",
    "\n",
    "R= **Both took approximately the same amount of time**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading data with `rpk`\n",
    "\n",
    "[](https://github.com/DataTalksClub/data-engineering-zoomcamp/blob/main/cohorts/2024/06-streaming/homework.md#reading-data-with-rpk)\n",
    "\n",
    "You can see the messages that you send to the topic with `rpk`:\n",
    "\n",
    "```shell\n",
    "rpk topic consume test-topic\n",
    "```\n",
    "\n",
    "Run the command above and send the messages one more time to see them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sending the taxi data\n",
    "\n",
    "[](https://github.com/DataTalksClub/data-engineering-zoomcamp/blob/main/cohorts/2024/06-streaming/homework.md#sending-the-taxi-data)\n",
    "\n",
    "Now let's send our actual data:\n",
    "\n",
    "- Read the green csv.gz file\n",
    "- We will only need these columns:\n",
    "    - `'lpep_pickup_datetime',`\n",
    "    - `'lpep_dropoff_datetime',`\n",
    "    - `'PULocationID',`\n",
    "    - `'DOLocationID',`\n",
    "    - `'passenger_count',`\n",
    "    - `'trip_distance',`\n",
    "    - `'tip_amount'`\n",
    "\n",
    "Iterate over the records in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pandas\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df\n",
    "df_green = pd.read_csv(\"https://github.com/DataTalksClub/nyc-tlc-data/releases/download/green/green_tripdata_2019-10.csv.gz\",\n",
    "                    compression=\"gzip\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>lpep_pickup_datetime</th>\n",
       "      <th>lpep_dropoff_datetime</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>ehail_fee</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>trip_type</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2019-10-01 00:26:02</td>\n",
       "      <td>2019-10-01 00:39:58</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>112</td>\n",
       "      <td>196</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.88</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>19.30</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2019-10-01 00:18:11</td>\n",
       "      <td>2019-10-01 00:22:38</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>43</td>\n",
       "      <td>263</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.80</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>9.05</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2019-10-01 00:09:31</td>\n",
       "      <td>2019-10-01 00:24:47</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>255</td>\n",
       "      <td>228</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.50</td>\n",
       "      <td>21.5</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>22.80</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2019-10-01 00:37:40</td>\n",
       "      <td>2019-10-01 00:41:49</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>181</td>\n",
       "      <td>181</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.90</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>6.80</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2019-10-01 00:08:13</td>\n",
       "      <td>2019-10-01 00:17:56</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>97</td>\n",
       "      <td>188</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.52</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>13.56</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VendorID lpep_pickup_datetime lpep_dropoff_datetime store_and_fwd_flag  \\\n",
       "0       2.0  2019-10-01 00:26:02   2019-10-01 00:39:58                  N   \n",
       "1       1.0  2019-10-01 00:18:11   2019-10-01 00:22:38                  N   \n",
       "2       1.0  2019-10-01 00:09:31   2019-10-01 00:24:47                  N   \n",
       "3       1.0  2019-10-01 00:37:40   2019-10-01 00:41:49                  N   \n",
       "4       2.0  2019-10-01 00:08:13   2019-10-01 00:17:56                  N   \n",
       "\n",
       "   RatecodeID  PULocationID  DOLocationID  passenger_count  trip_distance  \\\n",
       "0         1.0           112           196              1.0           5.88   \n",
       "1         1.0            43           263              1.0           0.80   \n",
       "2         1.0           255           228              2.0           7.50   \n",
       "3         1.0           181           181              1.0           0.90   \n",
       "4         1.0            97           188              1.0           2.52   \n",
       "\n",
       "   fare_amount  extra  mta_tax  tip_amount  tolls_amount  ehail_fee  \\\n",
       "0         18.0   0.50      0.5        0.00           0.0        NaN   \n",
       "1          5.0   3.25      0.5        0.00           0.0        NaN   \n",
       "2         21.5   0.50      0.5        0.00           0.0        NaN   \n",
       "3          5.5   0.50      0.5        0.00           0.0        NaN   \n",
       "4         10.0   0.50      0.5        2.26           0.0        NaN   \n",
       "\n",
       "   improvement_surcharge  total_amount  payment_type  trip_type  \\\n",
       "0                    0.3         19.30           2.0        1.0   \n",
       "1                    0.3          9.05           2.0        1.0   \n",
       "2                    0.3         22.80           2.0        1.0   \n",
       "3                    0.3          6.80           2.0        1.0   \n",
       "4                    0.3         13.56           1.0        1.0   \n",
       "\n",
       "   congestion_surcharge  \n",
       "0                   0.0  \n",
       "1                   0.0  \n",
       "2                   0.0  \n",
       "3                   0.0  \n",
       "4                   0.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check\n",
    "df_green.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select columns\n",
    "cols = [\n",
    "    'lpep_pickup_datetime',\n",
    "    'lpep_dropoff_datetime',\n",
    "    'PULocationID',\n",
    "    'DOLocationID',\n",
    "    'passenger_count',\n",
    "    'trip_distance',\n",
    "    'tip_amount'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply selection\n",
    "df_selection = df_green[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lpep_pickup_datetime': '2019-10-01 00:26:02', 'lpep_dropoff_datetime': '2019-10-01 00:39:58', 'PULocationID': 112, 'DOLocationID': 196, 'passenger_count': 1.0, 'trip_distance': 5.88, 'tip_amount': 0.0}\n"
     ]
    }
   ],
   "source": [
    "# test iterate\n",
    "t0 = time.time()\n",
    "for row in df_selection.itertuples(index=False):\n",
    "    row_dict = {col: getattr(row, col) for col in row._fields}\n",
    "    print(row_dict)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5: Sending the Trip Data\n",
    "\n",
    "[](https://github.com/DataTalksClub/data-engineering-zoomcamp/blob/main/cohorts/2024/06-streaming/homework.md#question-5-sending-the-trip-data)\n",
    "\n",
    "- Create a topic `green-trips` and send the data there\n",
    "- How much time in seconds did it take? (You can round it to a whole number)\n",
    "- Make sure you don't include sleeps in your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOPIC        STATUS\n",
      "green-trips  OK\n"
     ]
    }
   ],
   "source": [
    "!docker compose exec redpanda-1 rpk topic create green-trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to send data 67.47 seconds\n"
     ]
    }
   ],
   "source": [
    "# Note this step will be long XD\n",
    "topic_name = 'green-trips'\n",
    "t0 = time.time()\n",
    "\n",
    "for row in df_selection.itertuples(index=False):\n",
    "    row_dict = {col: getattr(row, col) for col in row._fields}\n",
    "    producer.send(topic_name, value=row_dict)\n",
    "    # print(row_dict)\n",
    "\n",
    "t1 = time.time()\n",
    "print(f'Time to send data {(t1 - t0):.2f} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the PySpark consumer\n",
    "\n",
    "Now let's read the data with PySpark.\n",
    "\n",
    "Spark needs a library (jar) to be able to connect to Kafka, so we need to tell PySpark that it needs to use it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "pyspark_version = pyspark.__version__\n",
    "kafka_jar_package = f\"org.apache.spark:spark-sql-kafka-0-10_2.12:{pyspark_version}\"\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName(\"GreenTripsConsumer\") \\\n",
    "    .config(\"spark.jars.packages\", kafka_jar_package) \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can connect to the stream:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "green_stream = spark \\\n",
    "    .readStream \\\n",
    "    .format(\"kafka\") \\\n",
    "    .option(\"kafka.bootstrap.servers\", \"localhost:9092\") \\\n",
    "    .option(\"subscribe\", \"green-trips\") \\\n",
    "    .option(\"startingOffsets\", \"earliest\") \\\n",
    "    .load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to test that we can consume from the stream, let's see what will be the first record there.\n",
    "\n",
    "In Spark streaming, the stream is represented as a sequence of small batches, each batch being a small RDD (or a small dataframe).\n",
    "\n",
    "So we can execute a function over each mini-batch. Let's run take(1) there to see what do we have in the stream:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(key=None, value=bytearray(b'{\"lpep_pickup_datetime\": \"2019-10-01 00:26:02\", \"lpep_dropoff_datetime\": \"2019-10-01 00:39:58\", \"PULocationID\": 112, \"DOLocationID\": 196, \"passenger_count\": 1.0, \"trip_distance\": 5.88, \"tip_amount\": 0.0}'), topic='green-trips', partition=0, offset=0, timestamp=datetime.datetime(2024, 3, 17, 12, 9, 43, 905000), timestampType=0)\n",
      "BatchID - 0\n",
      "[Row(lpep_pickup_datetime='2019-10-01 00:26:02', lpep_dropoff_datetime='2019-10-01 00:39:58', PULocationID=112, DOLocationID=196, passenger_count=1.0, trip_distance=5.88, tip_amount=0.0), Row(lpep_pickup_datetime='2019-10-01 00:18:11', lpep_dropoff_datetime='2019-10-01 00:22:38', PULocationID=43, DOLocationID=263, passenger_count=1.0, trip_distance=0.8, tip_amount=0.0), Row(lpep_pickup_datetime='2019-10-01 00:09:31', lpep_dropoff_datetime='2019-10-01 00:24:47', PULocationID=255, DOLocationID=228, passenger_count=2.0, trip_distance=7.5, tip_amount=0.0), Row(lpep_pickup_datetime='2019-10-01 00:37:40', lpep_dropoff_datetime='2019-10-01 00:41:49', PULocationID=181, DOLocationID=181, passenger_count=1.0, trip_distance=0.9, tip_amount=0.0), Row(lpep_pickup_datetime='2019-10-01 00:08:13', lpep_dropoff_datetime='2019-10-01 00:17:56', PULocationID=97, DOLocationID=188, passenger_count=1.0, trip_distance=2.52, tip_amount=2.26), Row(lpep_pickup_datetime='2019-10-01 00:35:01', lpep_dropoff_datetime='2019-10-01 00:43:40', PULocationID=65, DOLocationID=49, passenger_count=1.0, trip_distance=1.47, tip_amount=1.86), Row(lpep_pickup_datetime='2019-10-01 00:28:09', lpep_dropoff_datetime='2019-10-01 00:30:49', PULocationID=7, DOLocationID=179, passenger_count=1.0, trip_distance=0.6, tip_amount=1.0), Row(lpep_pickup_datetime='2019-10-01 00:28:26', lpep_dropoff_datetime='2019-10-01 00:32:01', PULocationID=41, DOLocationID=74, passenger_count=1.0, trip_distance=0.56, tip_amount=0.0), Row(lpep_pickup_datetime='2019-10-01 00:14:01', lpep_dropoff_datetime='2019-10-01 00:26:16', PULocationID=255, DOLocationID=49, passenger_count=1.0, trip_distance=2.42, tip_amount=0.0), Row(lpep_pickup_datetime='2019-10-01 00:03:03', lpep_dropoff_datetime='2019-10-01 00:17:13', PULocationID=130, DOLocationID=131, passenger_count=1.0, trip_distance=3.4, tip_amount=2.85)]\n"
     ]
    }
   ],
   "source": [
    "def peek(mini_batch, batch_id):\n",
    "    first_row = mini_batch.take(1)\n",
    "\n",
    "    if first_row:\n",
    "        print(first_row[0])\n",
    "\n",
    "query = green_stream.writeStream.foreachBatch(peek).start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see a record like this:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "query.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6. Parsing the data\n",
    "\n",
    "[](https://github.com/DataTalksClub/data-engineering-zoomcamp/blob/main/cohorts/2024/06-streaming/homework.md#question-6-parsing-the-data)\n",
    "\n",
    "The data is JSON, but currently it's in binary format. We need to parse it and turn it into a streaming dataframe with proper columns\n",
    "\n",
    "Similarly to PySpark, we define the schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import types\n",
    "\n",
    "schema = types.StructType() \\\n",
    "    .add(\"lpep_pickup_datetime\", types.StringType()) \\\n",
    "    .add(\"lpep_dropoff_datetime\", types.StringType()) \\\n",
    "    .add(\"PULocationID\", types.IntegerType()) \\\n",
    "    .add(\"DOLocationID\", types.IntegerType()) \\\n",
    "    .add(\"passenger_count\", types.DoubleType()) \\\n",
    "    .add(\"trip_distance\", types.DoubleType()) \\\n",
    "    .add(\"tip_amount\", types.DoubleType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "green_stream = green_stream \\\n",
    "  .select(F.from_json(F.col(\"value\").cast('STRING'), schema).alias(\"data\")) \\\n",
    "  .select(\"data.*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def debug_and_process(batch_df, batch_id):\n",
    "    print(f\"Batch ID: {batch_id}\")\n",
    "    batch_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = green_stream \\\n",
    "    .writeStream \\\n",
    "    .foreachBatch(debug_and_process) \\\n",
    "    .start()\n",
    "\n",
    "query.awaitTermination()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output Before:\n",
    "\n",
    "```shell\n",
    "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
    "|value\n",
    "                                                           |\n",
    "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
    "|{\"lpep_pickup_datetime\": \"2019-10-01 00:26:02\", \"lpep_dropoff_datetime\": \"2019-10-01 00:39:58\", \"PULocationID\": 112, \"DOLocationID\": 196, \"passenger_count\": 1.0, \"trip_distance\": 5.88, \"tip_amount\": 0.0}|\n",
    "|{\"lpep_pickup_datetime\": \"2019-10-01 00:18:11\", \"lpep_dropoff_datetime\": \"2019-10-01 00:22:38\", \"PULocationID\": 43, \"DOLocationID\": 263, \"passenger_count\": 1.0, \"trip_distance\": 0.8, \"tip_amount\": 0.0}  |\n",
    "|{\"lpep_pickup_datetime\": \"2019-10-01 00:09:31\", \"lpep_dropoff_datetime\": \"2019-10-01 00:24:47\", \"PULocationID\": 255, \"DOLocationID\": 228, \"passenger_count\": 2.0, \"trip_distance\": 7.5, \"tip_amount\": 0.0} |\n",
    "|{\"lpep_pickup_datetime\": \"2019-10-01 00:37:40\", \"lpep_dropoff_datetime\": \"2019-10-01 00:41:49\", \"PULocationID\": 181, \"DOLocationID\": 181, \"passenger_count\": 1.0, \"trip_distance\": 0.9, \"tip_amount\": 0.0} |\n",
    "|{\"lpep_pickup_datetime\": \"2019-10-01 00:08:13\", \"lpep_dropoff_datetime\": \"2019-10-01 00:17:56\", \"PULocationID\": 97, \"DOLocationID\": 188, \"passenger_count\": 1.0, \"trip_distance\": 2.52, \"tip_amount\": 2.26}|\n",
    "|{\"lpep_pickup_datetime\": \"2019-10-01 00:35:01\", \"lpep_dropoff_datetime\": \"2019-10-01 00:43:40\", \"PULocationID\": 65, \"DOLocationID\": 49, \"passenger_count\": 1.0, \"trip_distance\": 1.47, \"tip_amount\": 1.86} |\n",
    "|{\"lpep_pickup_datetime\": \"2019-10-01 00:28:09\", \"lpep_dropoff_datetime\": \"2019-10-01 00:30:49\", \"PULocationID\": 7, \"DOLocationID\": 179, \"passenger_count\": 1.0, \"trip_distance\": 0.6, \"tip_amount\": 1.0}   |\n",
    "|{\"lpep_pickup_datetime\": \"2019-10-01 00:28:26\", \"lpep_dropoff_datetime\": \"2019-10-01 00:32:01\", \"PULocationID\": 41, \"DOLocationID\": 74, \"passenger_count\": 1.0, \"trip_distance\": 0.56, \"tip_amount\": 0.0}  |\n",
    "|{\"lpep_pickup_datetime\": \"2019-10-01 00:14:01\", \"lpep_dropoff_datetime\": \"2019-10-01 00:26:16\", \"PULocationID\": 255, \"DOLocationID\": 49, \"passenger_count\": 1.0, \"trip_distance\": 2.42, \"tip_amount\": 0.0} |\n",
    "|{\"lpep_pickup_datetime\": \"2019-10-01 00:03:03\", \"lpep_dropoff_datetime\": \"2019-10-01 00:17:13\", \"PULocationID\": 130, \"DOLocationID\": 131, \"passenger_count\": 1.0, \"trip_distance\": 3.4, \"tip_amount\": 2.85}|\n",
    "|{\"lpep_pickup_datetime\": \"2019-10-01 00:07:10\", \"lpep_dropoff_datetime\": \"2019-10-01 00:23:38\", \"PULocationID\": 24, \"DOLocationID\": 74, \"passenger_count\": 3.0, \"trip_distance\": 3.18, \"tip_amount\": 0.0}  |\n",
    "|{\"lpep_pickup_datetime\": \"2019-10-01 00:25:48\", \"lpep_dropoff_datetime\": \"2019-10-01 00:49:52\", \"PULocationID\": 255, \"DOLocationID\": 188, \"passenger_count\": 1.0, \"trip_distance\": 4.7, \"tip_amount\": 1.0} |\n",
    "|{\"lpep_pickup_datetime\": \"2019-10-01 00:03:12\", \"lpep_dropoff_datetime\": \"2019-10-01 00:14:43\", \"PULocationID\": 129, \"DOLocationID\": 160, \"passenger_count\": 1.0, \"trip_distance\": 3.1, \"tip_amount\": 0.0} |\n",
    "|{\"lpep_pickup_datetime\": \"2019-10-01 00:44:56\", \"lpep_dropoff_datetime\": \"2019-10-01 00:51:06\", \"PULocationID\": 18, \"DOLocationID\": 169, \"passenger_count\": 1.0, \"trip_distance\": 1.19, \"tip_amount\": 0.25}|\n",
    "|{\"lpep_pickup_datetime\": \"2019-10-01 00:55:14\", \"lpep_dropoff_datetime\": \"2019-10-01 01:00:49\", \"PULocationID\": 223, \"DOLocationID\": 7, \"passenger_count\": 1.0, \"trip_distance\": 1.09, \"tip_amount\": 1.46} |\n",
    "|{\"lpep_pickup_datetime\": \"2019-10-01 00:06:06\", \"lpep_dropoff_datetime\": \"2019-10-01 00:11:05\", \"PULocationID\": 75, \"DOLocationID\": 262, \"passenger_count\": 1.0, \"trip_distance\": 1.24, \"tip_amount\": 2.01}|\n",
    "|{\"lpep_pickup_datetime\": \"2019-10-01 00:00:19\", \"lpep_dropoff_datetime\": \"2019-10-01 00:14:32\", \"PULocationID\": 97, \"DOLocationID\": 228, \"passenger_count\": 1.0, \"trip_distance\": 3.03, \"tip_amount\": 3.58}|\n",
    "|{\"lpep_pickup_datetime\": \"2019-10-01 00:09:31\", \"lpep_dropoff_datetime\": \"2019-10-01 00:20:41\", \"PULocationID\": 41, \"DOLocationID\": 74, \"passenger_count\": 1.0, \"trip_distance\": 2.03, \"tip_amount\": 2.16} |\n",
    "|{\"lpep_pickup_datetime\": \"2019-10-01 00:30:36\", \"lpep_dropoff_datetime\": \"2019-10-01 00:34:30\", \"PULocationID\": 41, \"DOLocationID\": 42, \"passenger_count\": 1.0, \"trip_distance\": 0.73, \"tip_amount\": 1.26} |\n",
    "|{\"lpep_pickup_datetime\": \"2019-10-01 00:58:32\", \"lpep_dropoff_datetime\": \"2019-10-01 01:05:08\", \"PULocationID\": 41, \"DOLocationID\": 116, \"passenger_count\": 1.0, \"trip_distance\": 1.48, \"tip_amount\": 0.0} |\n",
    "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
    "only showing top 20 rows\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output after parsing\n",
    "\n",
    "```shell\n",
    "Batch ID: 0\n",
    "+--------------------+---------------------+------------+------------+---------------+-------------+----------+\n",
    "|lpep_pickup_datetime|lpep_dropoff_datetime|PULocationID|DOLocationID|passenger_count|trip_distance|tip_amount|\n",
    "+--------------------+---------------------+------------+------------+---------------+-------------+----------+\n",
    "| 2019-10-01 00:26:02|  2019-10-01 00:39:58|         112|         196|            1.0|         5.88|       0.0|\n",
    "| 2019-10-01 00:18:11|  2019-10-01 00:22:38|          43|         263|            1.0|          0.8|       0.0|\n",
    "| 2019-10-01 00:09:31|  2019-10-01 00:24:47|         255|         228|            2.0|          7.5|       0.0|\n",
    "| 2019-10-01 00:37:40|  2019-10-01 00:41:49|         181|         181|            1.0|          0.9|       0.0|\n",
    "| 2019-10-01 00:08:13|  2019-10-01 00:17:56|          97|         188|            1.0|         2.52|      2.26|\n",
    "| 2019-10-01 00:35:01|  2019-10-01 00:43:40|          65|          49|            1.0|         1.47|      1.86|\n",
    "| 2019-10-01 00:28:09|  2019-10-01 00:30:49|           7|         179|            1.0|          0.6|       1.0|\n",
    "| 2019-10-01 00:28:26|  2019-10-01 00:32:01|          41|          74|            1.0|         0.56|       0.0|\n",
    "| 2019-10-01 00:14:01|  2019-10-01 00:26:16|         255|          49|            1.0|         2.42|       0.0|\n",
    "| 2019-10-01 00:03:03|  2019-10-01 00:17:13|         130|         131|            1.0|          3.4|      2.85|\n",
    "| 2019-10-01 00:07:10|  2019-10-01 00:23:38|          24|          74|            3.0|         3.18|       0.0|\n",
    "| 2019-10-01 00:25:48|  2019-10-01 00:49:52|         255|         188|            1.0|          4.7|       1.0|\n",
    "| 2019-10-01 00:03:12|  2019-10-01 00:14:43|         129|         160|            1.0|          3.1|       0.0|\n",
    "| 2019-10-01 00:44:56|  2019-10-01 00:51:06|          18|         169|            1.0|         1.19|      0.25|\n",
    "| 2019-10-01 00:55:14|  2019-10-01 01:00:49|         223|           7|            1.0|         1.09|      1.46|\n",
    "| 2019-10-01 00:06:06|  2019-10-01 00:11:05|          75|         262|            1.0|         1.24|      2.01|\n",
    "| 2019-10-01 00:00:19|  2019-10-01 00:14:32|          97|         228|            1.0|         3.03|      3.58|\n",
    "| 2019-10-01 00:09:31|  2019-10-01 00:20:41|          41|          74|            1.0|         2.03|      2.16|\n",
    "| 2019-10-01 00:30:36|  2019-10-01 00:34:30|          41|          42|            1.0|         0.73|      1.26|\n",
    "| 2019-10-01 00:58:32|  2019-10-01 01:05:08|          41|         116|            1.0|         1.48|       0.0|\n",
    "+--------------------+---------------------+------------+------------+---------------+-------------+----------+\n",
    "only showing top 20 rows\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7: Most popular destination\n",
    "\n",
    "[](https://github.com/DataTalksClub/data-engineering-zoomcamp/blob/main/cohorts/2024/06-streaming/homework.md#question-7-most-popular-destination)\n",
    "\n",
    "Now let's finally do some streaming analytics. We will see what's the most popular destination currently based on our stream of data (which ideally we should have sent with delays like we did in workshop 2)\n",
    "\n",
    "This is how you can do it:\n",
    "\n",
    "- Add a column \"timestamp\" using the `current_timestamp` function\n",
    "- Group by:\n",
    "    - 5 minutes window based on the timestamp column (`F.window(col(\"timestamp\"), \"5 minutes\")`)\n",
    "    - `\"DOLocationID\"`\n",
    "- Order by count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_destinations = green_stream.withColumn(\"timestamp\", F.current_timestamp()) \\\n",
    "    .groupBy(F.window(\"timestamp\", \"5 minutes\"), \"DOLocationID\") \\\n",
    "    .count() \\\n",
    "    .orderBy(F.col(\"count\").desc())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can print the output to the console using this code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = popular_destinations \\\n",
    "    .writeStream \\\n",
    "    .outputMode(\"complete\") \\\n",
    "    .format(\"console\") \\\n",
    "    .option(\"truncate\", \"false\") \\\n",
    "    .start()\n",
    "\n",
    "query.awaitTermination()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output:\n",
    "\n",
    "```shell\n",
    "python popular_dest.py\n",
    "+------------------------------------------+------------+-----+\n",
    "|window                                    |DOLocationID|count|\n",
    "+------------------------------------------+------------+-----+\n",
    "|{2024-03-17 13:50:00, 2024-03-17 13:55:00}|74          |17741|\n",
    "|{2024-03-17 13:50:00, 2024-03-17 13:55:00}|42          |15942|\n",
    "|{2024-03-17 13:50:00, 2024-03-17 13:55:00}|41          |14061|\n",
    "|{2024-03-17 13:50:00, 2024-03-17 13:55:00}|75          |12840|\n",
    "|{2024-03-17 13:50:00, 2024-03-17 13:55:00}|129         |11930|\n",
    "|{2024-03-17 13:50:00, 2024-03-17 13:55:00}|7           |11533|\n",
    "|{2024-03-17 13:50:00, 2024-03-17 13:55:00}|166         |10845|\n",
    "|{2024-03-17 13:50:00, 2024-03-17 13:55:00}|236         |7913 |\n",
    "|{2024-03-17 13:50:00, 2024-03-17 13:55:00}|223         |7542 |\n",
    "|{2024-03-17 13:50:00, 2024-03-17 13:55:00}|238         |7318 |\n",
    "|{2024-03-17 13:50:00, 2024-03-17 13:55:00}|82          |7292 |\n",
    "|{2024-03-17 13:50:00, 2024-03-17 13:55:00}|181         |7282 |\n",
    "|{2024-03-17 13:50:00, 2024-03-17 13:55:00}|95          |7244 |\n",
    "|{2024-03-17 13:50:00, 2024-03-17 13:55:00}|244         |6733 |\n",
    "|{2024-03-17 13:50:00, 2024-03-17 13:55:00}|61          |6606 |\n",
    "|{2024-03-17 13:50:00, 2024-03-17 13:55:00}|116         |6339 |\n",
    "|{2024-03-17 13:50:00, 2024-03-17 13:55:00}|138         |6144 |\n",
    "|{2024-03-17 13:50:00, 2024-03-17 13:55:00}|97          |6050 |\n",
    "|{2024-03-17 13:50:00, 2024-03-17 13:55:00}|49          |5221 |\n",
    "|{2024-03-17 13:50:00, 2024-03-17 13:55:00}|151         |5153 |\n",
    "+------------------------------------------+------------+-----+\n",
    "only showing top 20 rows\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_engineer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
