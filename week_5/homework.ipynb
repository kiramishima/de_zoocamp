{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import pandas as pd\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession, functions as F\n",
    "from pyspark.sql.types import StructType, StructField, StringType, TimestampType, IntegerType, DoubleType"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 5 Homework\n",
    "\n",
    "In this homework we'll put what we learned about Spark in practice.\n",
    "\n",
    "For this homework we will be using the FHV 2019-10 data found here. [FHV Data](https://github.com/DataTalksClub/nyc-tlc-data/releases/download/fhv/fhv_tripdata_2019-10.csv.gz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1:\n",
    "\n",
    "**Install Spark and PySpark**\n",
    "\n",
    "- Install Spark [OK]\n",
    "- Run PySpark [OK]\n",
    "- Create a local spark session [OK]\n",
    "- Execute spark.version [OK]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName('test') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.5.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyspark.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.5.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2:\n",
    "\n",
    "**FHV October 2019**\n",
    "\n",
    "Read the October 2019 FHV into a Spark Dataframe with a schema as we did in the lessons.\n",
    "\n",
    "Repartition the Dataframe to 6 partitions and save it to parquet.\n",
    "\n",
    "What is the average size of the Parquet (ending with .parquet extension) Files that were created (in MB)? Select the answer which most closely matches.\n",
    "\n",
    "- 1MB\n",
    "- 6MB\n",
    "- 25MB\n",
    "- 87MB\n",
    "\n",
    "R= **6MB**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data with pandas for obtain the schema\n",
    "pdf = pd.read_csv('data/raw/fhv/2019/10/fhv_tripdata_2019-10.csv.gz', compression='gzip', nrows=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dispatching_base_num       object\n",
       "pickup_datetime            object\n",
       "dropOff_datetime           object\n",
       "PUlocationID              float64\n",
       "DOlocationID              float64\n",
       "SR_Flag                   float64\n",
       "Affiliated_base_number     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dtypes\n",
    "pdf.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dispatching_base_num</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropOff_datetime</th>\n",
       "      <th>PUlocationID</th>\n",
       "      <th>DOlocationID</th>\n",
       "      <th>SR_Flag</th>\n",
       "      <th>Affiliated_base_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B00009</td>\n",
       "      <td>2019-10-01 00:23:00</td>\n",
       "      <td>2019-10-01 00:35:00</td>\n",
       "      <td>264.0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B00009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B00013</td>\n",
       "      <td>2019-10-01 00:11:29</td>\n",
       "      <td>2019-10-01 00:13:22</td>\n",
       "      <td>264.0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B00013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B00014</td>\n",
       "      <td>2019-10-01 00:11:43</td>\n",
       "      <td>2019-10-01 00:37:20</td>\n",
       "      <td>264.0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B00014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dispatching_base_num      pickup_datetime     dropOff_datetime  \\\n",
       "0               B00009  2019-10-01 00:23:00  2019-10-01 00:35:00   \n",
       "1               B00013  2019-10-01 00:11:29  2019-10-01 00:13:22   \n",
       "2               B00014  2019-10-01 00:11:43  2019-10-01 00:37:20   \n",
       "\n",
       "   PUlocationID  DOlocationID  SR_Flag Affiliated_base_number  \n",
       "0         264.0         264.0      NaN                 B00009  \n",
       "1         264.0         264.0      NaN                 B00013  \n",
       "2         264.0         264.0      NaN                 B00014  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first 3 elements\n",
    "pdf.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('dispatching_base_num', StringType(), True), StructField('pickup_datetime', StringType(), True), StructField('dropOff_datetime', StringType(), True), StructField('PUlocationID', DoubleType(), True), StructField('DOlocationID', DoubleType(), True), StructField('SR_Flag', DoubleType(), True), StructField('Affiliated_base_number', StringType(), True)])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the schema\n",
    "spark.createDataFrame(pdf).schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fhv schema\n",
    "fhv_schema = StructType([\n",
    "    StructField('dispatching_base_num', StringType(), True), \n",
    "    StructField('pickup_datetime', TimestampType(), True), \n",
    "    StructField('dropOff_datetime', TimestampType(), True), \n",
    "    StructField('PUlocationID', IntegerType(), True), \n",
    "    StructField('DOlocationID', IntegerType(), True), \n",
    "    StructField('SR_Flag', DoubleType(), True), \n",
    "    StructField('Affiliated_base_number', StringType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load csv data\n",
    "fhv_df = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .schema(fhv_schema) \\\n",
    "    .csv('data/raw/fhv/2019/10/fhv_tripdata_2019-10.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dispatching_base_num: string (nullable = true)\n",
      " |-- pickup_datetime: timestamp (nullable = true)\n",
      " |-- dropOff_datetime: timestamp (nullable = true)\n",
      " |-- PUlocationID: integer (nullable = true)\n",
      " |-- DOlocationID: integer (nullable = true)\n",
      " |-- SR_Flag: double (nullable = true)\n",
      " |-- Affiliated_base_number: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Schema\n",
    "fhv_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repartition the Dataframe to 6 partitions and save it to parquet\n",
    "fhv_df \\\n",
    "    .repartition(6) \\\n",
    "    .write.parquet('data/pq/fhv/2019/10', mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 39M\n",
      "-rw-r--r-- 1 kiramishima 197609    0 Feb 26 00:49 _SUCCESS\n",
      "-rw-r--r-- 1 kiramishima 197609 6.4M Feb 26 00:49 part-00000-d136129f-f205-451c-93d1-d1badffbdc33-c000.snappy.parquet\n",
      "-rw-r--r-- 1 kiramishima 197609 6.4M Feb 26 00:49 part-00001-d136129f-f205-451c-93d1-d1badffbdc33-c000.snappy.parquet\n",
      "-rw-r--r-- 1 kiramishima 197609 6.4M Feb 26 00:49 part-00002-d136129f-f205-451c-93d1-d1badffbdc33-c000.snappy.parquet\n",
      "-rw-r--r-- 1 kiramishima 197609 6.4M Feb 26 00:49 part-00003-d136129f-f205-451c-93d1-d1badffbdc33-c000.snappy.parquet\n",
      "-rw-r--r-- 1 kiramishima 197609 6.4M Feb 26 00:49 part-00004-d136129f-f205-451c-93d1-d1badffbdc33-c000.snappy.parquet\n",
      "-rw-r--r-- 1 kiramishima 197609 6.4M Feb 26 00:49 part-00005-d136129f-f205-451c-93d1-d1badffbdc33-c000.snappy.parquet\n"
     ]
    }
   ],
   "source": [
    "!ls -lh data/pq/fhv/2019/10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3:\n",
    "\n",
    "**Count records**\n",
    "\n",
    "How many taxi trips were there on the 15th of October?\n",
    "\n",
    "Consider only trips that started on the 15th of October.\n",
    "\n",
    "- 108,164\n",
    "- 12,856\n",
    "- 452,470\n",
    "- 62,610\n",
    "\n",
    "R= **62610**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from parquet\n",
    "df_fhv = spark.read.parquet('data/pq/fhv/2019/10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dispatching_base_num: string (nullable = true)\n",
      " |-- pickup_datetime: timestamp (nullable = true)\n",
      " |-- dropOff_datetime: timestamp (nullable = true)\n",
      " |-- PUlocationID: integer (nullable = true)\n",
      " |-- DOlocationID: integer (nullable = true)\n",
      " |-- SR_Flag: double (nullable = true)\n",
      " |-- Affiliated_base_number: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check schema\n",
    "df_fhv.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new columns\n",
    "df_fhv = df_fhv \\\n",
    "    .withColumn('pickup_date', F.to_date(df_fhv['pickup_datetime'])) \\\n",
    "    .withColumn('dropoff_date', F.to_date(df_fhv['dropOff_datetime']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dispatching_base_num: string (nullable = true)\n",
      " |-- pickup_datetime: timestamp (nullable = true)\n",
      " |-- dropOff_datetime: timestamp (nullable = true)\n",
      " |-- PUlocationID: integer (nullable = true)\n",
      " |-- DOlocationID: integer (nullable = true)\n",
      " |-- SR_Flag: double (nullable = true)\n",
      " |-- Affiliated_base_number: string (nullable = true)\n",
      " |-- pickup_date: date (nullable = true)\n",
      " |-- dropoff_date: date (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_fhv.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62610"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fhv \\\n",
    "    .filter(df_fhv['pickup_date'] == F.lit('2019-10-15') ) \\\n",
    "    .count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative\n",
    "df_fhv.createOrReplaceTempView('trips_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|total_records|\n",
      "+-------------+\n",
      "|        62610|\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT\n",
    "    COUNT(1) AS total_records\n",
    "FROM trips_data\n",
    "WHERE pickup_date == '2019-10-15'\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4:\n",
    "\n",
    "**Longest trip for each day**\n",
    "\n",
    "What is the length of the longest trip in the dataset in hours?\n",
    "\n",
    "- 631,152.50 Hours\n",
    "- 243.44 Hours\n",
    "- 7.68 Hours\n",
    "- 3.32 Hours\n",
    "\n",
    "R= **631,152.50**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+-----------+------------+\n",
      "|dispatching_base_num|    pickup_datetime|   dropOff_datetime|PUlocationID|DOlocationID|SR_Flag|Affiliated_base_number|pickup_date|dropoff_date|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+-----------+------------+\n",
      "|              B01843|2019-10-29 16:49:00|2019-10-29 20:29:00|         264|         264|   NULL|                  NULL| 2019-10-29|  2019-10-29|\n",
      "|              B01559|2019-10-24 08:37:30|2019-10-24 08:55:30|         264|         264|   NULL|                B01559| 2019-10-24|  2019-10-24|\n",
      "|              B00911|2019-10-18 15:43:00|2019-10-18 17:50:37|         264|         244|   NULL|                B00911| 2019-10-18|  2019-10-18|\n",
      "|              B02795|2019-10-26 11:06:00|2019-10-26 12:20:39|          39|          49|   NULL|                B02795| 2019-10-26|  2019-10-26|\n",
      "|              B01349|2019-10-14 19:00:00|2019-10-14 20:15:00|         264|         264|   NULL|                B01349| 2019-10-14|  2019-10-14|\n",
      "|              B00112|2019-10-18 17:00:17|2019-10-18 17:33:29|         264|         261|   NULL|                B00112| 2019-10-18|  2019-10-18|\n",
      "|              B01340|2019-10-07 14:43:19|2019-10-07 15:06:27|         264|         174|   NULL|                B01340| 2019-10-07|  2019-10-07|\n",
      "|              B00856|2019-10-31 01:57:37|2019-10-31 02:01:42|         264|          61|   NULL|                B02889| 2019-10-31|  2019-10-31|\n",
      "|              B01800|2019-10-16 08:44:00|2019-10-16 09:47:00|         264|         264|   NULL|                B01800| 2019-10-16|  2019-10-16|\n",
      "|              B03055|2019-10-28 06:58:20|2019-10-28 07:03:48|         264|         108|   NULL|                B03055| 2019-10-28|  2019-10-28|\n",
      "|              B01087|2019-10-09 21:35:52|2019-10-09 21:50:08|         261|         133|   NULL|                B01087| 2019-10-09|  2019-10-09|\n",
      "|              B00802|2019-10-21 02:01:44|2019-10-21 02:04:55|         264|          14|   NULL|                B00802| 2019-10-21|  2019-10-21|\n",
      "|              B03160|2019-10-25 11:11:00|2019-10-25 11:18:00|         205|         205|   NULL|                B02875| 2019-10-25|  2019-10-25|\n",
      "|              B00837|2019-10-08 08:34:52|2019-10-08 11:01:32|         264|         264|   NULL|                B00837| 2019-10-08|  2019-10-08|\n",
      "|              B01285|2019-10-02 14:24:12|2019-10-02 14:34:54|         264|         167|   NULL|                B01285| 2019-10-02|  2019-10-02|\n",
      "|              B00756|2019-10-10 08:38:00|2019-10-10 08:46:00|         264|         264|   NULL|                B02875| 2019-10-10|  2019-10-10|\n",
      "|              B00037|2019-10-20 15:52:40|2019-10-20 16:05:31|         264|         149|   NULL|                B00037| 2019-10-20|  2019-10-20|\n",
      "|              B00477|2019-10-09 08:21:32|2019-10-09 08:45:57|         142|           1|   NULL|                B00477| 2019-10-09|  2019-10-09|\n",
      "|              B01843|2019-10-07 05:56:00|2019-10-07 07:45:00|         264|         264|   NULL|                  NULL| 2019-10-07|  2019-10-07|\n",
      "|              B02849|2019-10-04 04:28:50|2019-10-04 04:36:36|         264|          76|   NULL|                B02849| 2019-10-04|  2019-10-04|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+-----------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_fhv.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fhv2 = df_fhv \\\n",
    "    .withColumn('trip_duration', \\\n",
    "        (F.col(\"dropOff_datetime\").cast(\"long\") - \\\n",
    "        F.col('pickup_datetime').cast(\"long\")) / 3600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|    trip_duration|\n",
      "+-----------------+\n",
      "|         631153.5|\n",
      "|         631152.5|\n",
      "|87672.44083333333|\n",
      "|70129.02805555555|\n",
      "|           8794.0|\n",
      "+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_fhv2 \\\n",
    "    .select('trip_duration') \\\n",
    "    .orderBy(F.desc('trip_duration')) \\\n",
    "    .show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fhv2.createOrReplaceTempView('trips_data_duration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|max(trip_duration)|\n",
      "+------------------+\n",
      "|          631153.5|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT MAX(trip_duration)\n",
    "FROM trips_data_duration\n",
    "\"\"\").show()\n",
    "\n",
    "# The answers don't have 631153.5, so, the correct answer is 631152.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5:\n",
    "\n",
    "**User Interface**\n",
    "\n",
    "Spark’s User Interface which shows the application's dashboard runs on which local port?\n",
    "\n",
    "- 80\n",
    "- 443\n",
    "- 4040\n",
    "- 8080\n",
    "\n",
    "R= **4040**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6:\n",
    "\n",
    "**Least frequent pickup location zone**\n",
    "\n",
    "Load the zone lookup data into a temp view in Spark  \n",
    "[Zone Data](https://github.com/DataTalksClub/nyc-tlc-data/releases/download/misc/taxi_zone_lookup.csv)\n",
    "\n",
    "Using the zone lookup data and the FHV October 2019 data, what is the name of the LEAST frequent pickup location Zone?  \n",
    "\n",
    "- East Chelsea\n",
    "- Jamaica Bay\n",
    "- Union Sq\n",
    "- Crown Heights North\n",
    "\n",
    "R= **Jamaica Bay**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('LocationID', LongType(), True), StructField('Borough', StringType(), True), StructField('Zone', StringType(), True), StructField('service_zone', StringType(), True)])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zdf = pd.read_csv('https://github.com/DataTalksClub/nyc-tlc-data/releases/download/misc/taxi_zone_lookup.csv')\n",
    "spark.createDataFrame(zdf).schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zones Schema\n",
    "zones_schema = StructType([\n",
    "    StructField('LocationID', IntegerType(), True), \n",
    "    StructField('Borough', StringType(), True), \n",
    "    StructField('Zone', StringType(), True), \n",
    "    StructField('service_zone', StringType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load csv data\n",
    "df_zones = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .schema(zones_schema) \\\n",
    "    .csv('data/raw/zones/taxi_zone_lookup.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create temp view\n",
    "df_zones.createTempView('zones_lookup')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+--------------------+------------+\n",
      "|LocationID|      Borough|                Zone|service_zone|\n",
      "+----------+-------------+--------------------+------------+\n",
      "|         1|          EWR|      Newark Airport|         EWR|\n",
      "|         2|       Queens|         Jamaica Bay|   Boro Zone|\n",
      "|         3|        Bronx|Allerton/Pelham G...|   Boro Zone|\n",
      "|         4|    Manhattan|       Alphabet City| Yellow Zone|\n",
      "|         5|Staten Island|       Arden Heights|   Boro Zone|\n",
      "|         6|Staten Island|Arrochar/Fort Wad...|   Boro Zone|\n",
      "|         7|       Queens|             Astoria|   Boro Zone|\n",
      "|         8|       Queens|        Astoria Park|   Boro Zone|\n",
      "|         9|       Queens|          Auburndale|   Boro Zone|\n",
      "|        10|       Queens|        Baisley Park|   Boro Zone|\n",
      "+----------+-------------+--------------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show data\n",
    "spark.sql(\"\"\"\n",
    "SELECT * FROM zones_lookup\n",
    "LIMIT 10\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+\n",
      "|                Zone|count(1)|\n",
      "+--------------------+--------+\n",
      "|         Jamaica Bay|       1|\n",
      "|Governor's Island...|       2|\n",
      "| Green-Wood Cemetery|       5|\n",
      "|       Broad Channel|       8|\n",
      "|     Highbridge Park|      14|\n",
      "|        Battery Park|      15|\n",
      "|Saint Michaels Ce...|      23|\n",
      "|Breezy Point/Fort...|      25|\n",
      "|Marine Park/Floyd...|      26|\n",
      "|        Astoria Park|      29|\n",
      "|    Inwood Hill Park|      39|\n",
      "|       Willets Point|      47|\n",
      "|Forest Park/Highl...|      53|\n",
      "|  Brooklyn Navy Yard|      57|\n",
      "|        Crotona Park|      62|\n",
      "|        Country Club|      77|\n",
      "|     Freshkills Park|      89|\n",
      "|       Prospect Park|      98|\n",
      "|     Columbia Street|     105|\n",
      "|  South Williamsburg|     110|\n",
      "+--------------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Solution 1\n",
    "spark.sql(\"\"\"\n",
    "SELECT\n",
    "    pickup_location.Zone,\n",
    "    COUNT(1)\n",
    "FROM trips_data\n",
    "INNER JOIN zones_lookup AS pickup_location\n",
    "    ON trips_data.PUlocationID = pickup_location.LocationID\n",
    "GROUP BY 1\n",
    "ORDER BY 2 ASC\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+----------+-------+---------------+------------+\n",
      "|dispatching_base_num|    pickup_datetime|   dropOff_datetime|PUlocationID|DOlocationID|SR_Flag|Affiliated_base_number|LocationID|Borough|           Zone|service_zone|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+----------+-------+---------------+------------+\n",
      "|              B00009|2019-10-01 00:23:00|2019-10-01 00:35:00|         264|         264|   NULL|                B00009|       264|Unknown|             NV|         N/A|\n",
      "|              B00013|2019-10-01 00:11:29|2019-10-01 00:13:22|         264|         264|   NULL|                B00013|       264|Unknown|             NV|         N/A|\n",
      "|              B00014|2019-10-01 00:11:43|2019-10-01 00:37:20|         264|         264|   NULL|                B00014|       264|Unknown|             NV|         N/A|\n",
      "|              B00014|2019-10-01 00:56:29|2019-10-01 00:57:47|         264|         264|   NULL|                B00014|       264|Unknown|             NV|         N/A|\n",
      "|              B00014|2019-10-01 00:23:09|2019-10-01 00:28:27|         264|         264|   NULL|                B00014|       264|Unknown|             NV|         N/A|\n",
      "|     B00021         |2019-10-01 00:00:48|2019-10-01 00:07:12|         129|         129|   NULL|       B00021         |       129| Queens|Jackson Heights|   Boro Zone|\n",
      "|     B00021         |2019-10-01 00:47:23|2019-10-01 00:53:25|          57|          57|   NULL|       B00021         |        57| Queens|         Corona|   Boro Zone|\n",
      "|     B00021         |2019-10-01 00:10:06|2019-10-01 00:19:50|         173|         173|   NULL|       B00021         |       173| Queens|   North Corona|   Boro Zone|\n",
      "|     B00021         |2019-10-01 00:51:37|2019-10-01 01:06:14|         226|         226|   NULL|       B00021         |       226| Queens|      Sunnyside|   Boro Zone|\n",
      "|     B00021         |2019-10-01 00:28:23|2019-10-01 00:34:33|          56|          56|   NULL|       B00021         |        56| Queens|         Corona|   Boro Zone|\n",
      "|     B00021         |2019-10-01 00:31:17|2019-10-01 00:51:52|          82|          82|   NULL|       B00021         |        82| Queens|       Elmhurst|   Boro Zone|\n",
      "|              B00037|2019-10-01 00:07:41|2019-10-01 00:15:23|         264|          71|   NULL|                B00037|       264|Unknown|             NV|         N/A|\n",
      "|              B00037|2019-10-01 00:13:38|2019-10-01 00:25:51|         264|          39|   NULL|                B00037|       264|Unknown|             NV|         N/A|\n",
      "|              B00037|2019-10-01 00:42:40|2019-10-01 00:53:47|         264|         188|   NULL|                B00037|       264|Unknown|             NV|         N/A|\n",
      "|              B00037|2019-10-01 00:58:46|2019-10-01 01:10:11|         264|          91|   NULL|                B00037|       264|Unknown|             NV|         N/A|\n",
      "|              B00037|2019-10-01 00:09:49|2019-10-01 00:14:37|         264|          71|   NULL|                B00037|       264|Unknown|             NV|         N/A|\n",
      "|              B00037|2019-10-01 00:22:35|2019-10-01 00:36:53|         264|          35|   NULL|                B00037|       264|Unknown|             NV|         N/A|\n",
      "|              B00037|2019-10-01 00:54:27|2019-10-01 01:03:37|         264|          61|   NULL|                B00037|       264|Unknown|             NV|         N/A|\n",
      "|              B00037|2019-10-01 00:08:12|2019-10-01 00:28:47|         264|         198|   NULL|                B00037|       264|Unknown|             NV|         N/A|\n",
      "|              B00053|2019-10-01 00:05:24|2019-10-01 00:53:03|         264|         264|   NULL|                  #N/A|       264|Unknown|             NV|         N/A|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+----------+-------+---------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Solution 2: Join fhv_df with df_zones\n",
    "fhv_zones_df = fhv_df.join(df_zones, fhv_df.PUlocationID == df_zones.LocationID)\n",
    "fhv_zones_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "fhv_zones_df.createOrReplaceTempView('fhv_zones')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+\n",
      "|                Zone|count(1)|\n",
      "+--------------------+--------+\n",
      "|         Jamaica Bay|       1|\n",
      "|Governor's Island...|       2|\n",
      "| Green-Wood Cemetery|       5|\n",
      "|       Broad Channel|       8|\n",
      "|     Highbridge Park|      14|\n",
      "|        Battery Park|      15|\n",
      "|Saint Michaels Ce...|      23|\n",
      "|Breezy Point/Fort...|      25|\n",
      "|Marine Park/Floyd...|      26|\n",
      "|        Astoria Park|      29|\n",
      "|    Inwood Hill Park|      39|\n",
      "|       Willets Point|      47|\n",
      "|Forest Park/Highl...|      53|\n",
      "|  Brooklyn Navy Yard|      57|\n",
      "|        Crotona Park|      62|\n",
      "|        Country Club|      77|\n",
      "|     Freshkills Park|      89|\n",
      "|       Prospect Park|      98|\n",
      "|     Columbia Street|     105|\n",
      "|  South Williamsburg|     110|\n",
      "+--------------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT Zone, count(*)\n",
    "FROM fhv_zones\n",
    "GROUP BY Zone\n",
    "ORDER BY 2 ASC\n",
    "\"\"\").show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_engineer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
